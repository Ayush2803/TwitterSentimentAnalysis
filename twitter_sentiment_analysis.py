# -*- coding: utf-8 -*-
"""Twitter Sentiment Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hiN4leWD9wRupMqGGjFYhtZV2kRw6ZwP

#Twitter Sentiment Analysis

Uses Naive Bayes Classifier. 
TextBlob library- with inbuilt Naive Bayes Classifier
"""

# Minor Project
# AYUSH SHARMA
# 2K19/SE/027

# Description: Sentiment analysis on tweets parsed directly from live Twitter feed

"""#Import Libraries and Define Functions"""

import pandas as pd
import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import numpy as np
import re
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
import os

clearConsole = lambda: os.system('cls' if os.name in ('nt', 'dos') else 'clear')

# Function to clean the tweets text
# Uses Regular Expressions (re) library

def cleanText(text):
  text= re.sub(r'@[A-Za-z0-9]+', '', text)  #Removes @ mentions
  text=re.sub(r'#', '', text)               #Removes hash tags
  text=re.sub(r'RT[\s]+', '', text)         #Remove Re tweet symbol
  text=re.sub(r'https?:\/\/\S+', '', text)  #Removes any hyperlinks from the tweet

  return text

#Function to calculate subjectivity of a tweet
#Using TextBlob

def getSubjectivity(text):
  return TextBlob(text).sentiment.subjectivity

#Function to calculate polarity of a tweet
#using TextBlob

def getPolarity(text):
  return TextBlob(text).sentiment.polarity

#Analyse

def getAnalysis(score):
  if score<0:
    return 'Negative'
  elif score==0:
    return 'Neutral'
  else:
    return 'Positive'

# Rumour Detection
def fact_opinion(score, t1=0.25, t2=0.75):
  if score<t1:
    return 'Fact'
  elif score<t2:
    return 'Neutral'
  else:
    return 'Opinion'

"""#Twiiter Authentication"""

# Twitter API credentials
# Which are secret so I can't reveal them
# Hence I will upload them from csv file I made
cred= pd.read_csv('credentials.csv')

ck = cred['consumer_key'][0]
cs = cred['consumer_secret'][0]
ak = cred['access_key'][0]
as_ = cred['access_secret'][0]

# Authenticate
auth = tweepy.OAuthHandler(ck,cs)

# Access 
auth.set_access_token(ak, as_)

#API
api= tweepy.API(auth, wait_on_rate_limit=True)

"""#Gather Tweets"""

#Initialise the posts array
num_posts=500   #Number of tweets you want to extract
posts=[]

# Listener Object

class Listener (tweepy.StreamListener):

  def on_status(self, status):
    global num_posts
    if num_posts>0:
      posts.append(status.text)
      num_posts-=1
    
    else:
      print("Collected desired number of posts")
      return False

  def on_error(self, status_code):
    if status_code == 420:
      return False

listener_= Listener()

myStream = tweepy.Stream(auth = api.auth, listener=listener_)

myStream.filter(track=['Indian Cricket Team', 'Cricket', 'World Cup', 'T20', 'Virat Kohli', 'Rohit Sharma', 
                       'Jasprit Bumrah', 'Ind vs NZ', 'Ind vs Pak', 'India vs New Zealand', 'India vs Pakistan', 'Test match'], languages=['en'])

len(posts)

for tweet in posts[0:5]:
  print(tweet+'\n')

df = pd.DataFrame([tweet for tweet in posts], columns=['Tweets'])
df.head()

df.to_csv('tweets_posts.csv')

"""# Clean Tweets"""

#Clean the Tweets text

df['Tweets']=df['Tweets'].apply(cleanText)

df

df.to_csv("tweets_clean.csv")

"""#Sentiment Analysis"""

df= pd.read_csv('tweets_clean.csv')

# Get the subjectivity and polarity of tweets

# Subjectivity- [0 to 1]. More subjective means the tweet is more opinionated than fact
# Polarity- [-1 to 1]. Positive means good, negative means bad

df['Subjectivity']= df['Tweets'].apply(getSubjectivity)
df['Polarity']=df['Tweets'].apply(getPolarity)

#Display
df

# Plot Word Cloud

allWords= ' '.join( [twts for twts in df['Tweets']] )
wordCloud= WordCloud(width=500, height=300, random_state=21, max_font_size=119).generate(allWords)

plt.imshow(wordCloud, interpolation='bilinear')
plt.axis('off')
plt.show()

# Get Analysis

df['Analysis']=df['Polarity'].apply(getAnalysis)

#Display
df

# See whether the tweets are fact based or opinionated

df['Facts']= df['Subjectivity'].apply(fact_opinion)

df

# Display all the Positive Tweets

ptweets= df[df.Analysis=='Positive']
ptweets= ptweets['Tweets']
ptweets

# Display all the Negative Tweets

ntweets= df[df.Analysis=='Negative']
ntweets= ntweets['Tweets']
ntweets

# Plot the sentiment analysis

fig = plt.figure(figsize=(8,6))
plt.scatter(df['Polarity'],df['Subjectivity'])
plt.title("Sentiment Analysis")
plt.xlabel("Polarity")
plt.ylabel("Subjectivity")
plt.show()

# Visualise the percentage of positive and negative tweets

pos = (ptweets.shape[0]/df.shape[0])*100
neg = (ntweets.shape[0]/df.shape[0])*100

print("Positive: "+ str(pos)+ "%\nNegative: "+ str(neg))

fig= plt.figure(figsize=(8,6))
df['Analysis'].value_counts().plot(kind='bar')
plt.title("Analysis of kind of tweets")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

# Visualise the number of tweets that are factual vs the tweets that are biased

fig= plt.figure(figsize=(8,6))
df['Facts'].value_counts().plot(kind='bar')
plt.title("Bias in tweets- Rumour Analysis")
plt.xlabel("Fact or Opinion")
plt.ylabel("Count")
plt.show()

df.to_csv('tweets_data.csv')

